#!/usr/bin/env python3
"""
è§†é¢‘åˆ†æè„šæœ¬ - VibeEnglish
ç”¨äºç”Ÿæˆå¸¦è¯æ±‡é«˜äº®çš„è‹±æ–‡æ–‡ç¨¿

ä½¿ç”¨æ–¹æ³•ï¼š
1. GLM-4V-Flash API (å¤šæ¨¡æ€è§†è§‰åˆ†æ)
2. spacy åˆ†è¯å’Œè¯æ€§æ ‡æ³¨
3. wordfreq è¯æ±‡é¢‘ç‡å’Œéš¾åº¦è®¡ç®—
4. CEFR åˆ†çº§æ ‡å‡†
"""

import os
import json
import requests
from typing import List, Dict, Optional

# ============== é…ç½® ==============
API_URL = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
API_KEY = "d836e1d-4236-4ed0-9e25-d9d35d54973"  # æ›¿æ¢ä¸ºå®é™… API Key
FRAME_DIR = "temp_frames"
OUTPUT_FILE = "video_narrative.json"

# ============== Prompt æ¨¡æ¿ ==============
PROMPT_TEMPLATES = {
  "casual": """### Role
Expert English Teacher & Visual Analyst specialized in casual spoken English.

### Task
Write a natural, descriptive narrative sentence for this image.

### Guidelines
- Use descriptive English (15-25 words)
- Focus on communication and meaning
- Use simple, everyday vocabulary similar to daily conversation
- Include common contractions (can't, don't, I'm, you're)
- Be accurate with object detection
- Output ONLY valid JSON

### Example
- "It's a nice day. Let's take a walk."
- "What do you think about that?"
- "I see something moving over there."

### Output Format (Strict JSON ONLY)
{{
  "video_narrative": [
    {{
      "frame_index": 0,
      "timestamp": "00:00",
      "sentence": "Your descriptive sentence here."
    }}
  ],
  "detected_objects": [
    {{
      "label": "noun from your sentence",
      "boxes": [[ymin, xmin, ymax, xmax]]
    }}
  ]
}}""",

  "beginner": """### Role
Expert English Teacher & Visual Analyst specialized in beginner-friendly English.

### Task
Write a clear, simple narrative sentence for this image.

### Guidelines
- Use simple, clear English (8-12 words)
- Use high-frequency, familiar words from top 2000
- Use basic grammar (present simple tense, simple structures)
- Use short, clear sentences (8-12 words)
- Focus on fundamental vocabulary (have, is, are, was, were, can, will, would, should)
- Avoid complex sentence structures
- Avoid slang or overly colloquial expressions
- Be encouraging and supportive for beginners

### Example
- "The cat is black and white."
- "I have a red apple."
- "There are three birds on tree."
- "This book is for you."
- "The dog is big."

### Output Format (Strict JSON ONLY)
{{
  "video_narrative": [
    {{
      "frame_index": 0,
      "timestamp": "00:00",
      "sentence": "Your simple sentence here."
    }}
  ],
  "detected_objects": [
    {{
      "label": "noun from your sentence",
      "boxes": [[ymin, xmin, ymax, xmax]]
    }}
  ]
}}""",

  "literary": """### Role
Expert English Teacher & Visual Analyst specialized in literary prose.

### Task
Write an elegant, descriptive narrative sentence for this image.

### Guidelines
- Use descriptive, literary English (15-25 words)
- Use varied sentence structures and connectives
- Include figurative language and imagery where appropriate
- Create a sense of atmosphere and mood
- Use sophisticated vocabulary and expressions
- Employ literary techniques (metaphor, simile, personification)
- Focus on narrative quality and stylistic elegance

### Example
- "The rabbit's movements were as fluid as water, its fur catching morning light."
- "Butterflies fluttered like dancing flowers, their wings painted with sunset colors."
- "The meadow stretched endlessly, a tapestry of greens and gold under vast sky."
- "Time stood still, captured in the quiet elegance of this peaceful moment."
- "The old house whispered stories of forgotten days, its windows like eyes watching the world pass by."
- "Autumn leaves danced through the crisp air, each one a farewell note to summer's embrace."
- "The mountain peak pierced through the clouds, a silent guardian watching over the tranquil valley below."

### Output Format (Strict JSON ONLY)
{{
  "video_narrative": [
    {{
      "frame_index": 0,
      "timestamp": "00:00",
      "sentence": "Your literary sentence here."
    }}
  ],
  "detected_objects": [
    {{
      "label": "noun from your sentence",
      "boxes": [[ymin, xmin, ymax, xmax]]
    }}
  ]
}}"""
}

# ============== è§†é¢‘å¸§è·å– ==============
def get_video_frames(frame_dir: str = FRAME_DIR, max_frames: int = 10) -> List[str]:
    """è·å–è§†é¢‘å¸§åˆ—è¡¨
    
    Args:
        frame_dir: å¸§ç›®å½•
        max_frames: æœ€å¤§å¸§æ•°
    
    Returns:
        å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆbase64ç¼–ç ï¼‰
    """
    frames = []
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(frame_dir):
        print(f"âŒ Error: Frame directory not found: {frame_dir}")
        return frames
    
    # è·å–æ‰€æœ‰ JPG æ–‡ä»¶
    frame_files = sorted([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])
    
    # é™åˆ¶å¸§æ•°
    frame_files = frame_files[:max_frames]
    
    print(f"ğŸ“¹ Found {len(frame_files)} frames in {frame_dir}")
    
    # è¯»å–å¹¶ç¼–ç ä¸º base64
    for i, filename in enumerate(frame_files):
        filepath = os.path.join(frame_dir, filename)
        
        try:
            with open(filepath, 'rb') as f:
                image_data = f.read()
            
            # è½¬æ¢ä¸º base64
            import base64
            base64_data = base64.b64encode(image_data).decode('utf-8')
            frames.append(base64_data)
            
            print(f"âœ… Frame {i+1}/{len(frame_files)}: {filename}")
            
        except Exception as e:
            print(f"âŒ Error reading {filename}: {e}")
            continue
    
    return frames

# ============== GLM-4V API è°ƒç”¨ ==============
def call_glm_api(frame_base64: str, style: str = 'casual') -> Optional[dict]:
    """è°ƒç”¨ GLM-4V-Flash API è¿›è¡Œè§†é¢‘åˆ†æ
    
    Args:
        frame_base64: è§†é¢‘å¸§çš„ base64 ç¼–ç 
        style: Prompt é£æ ¼ (casual, beginner, literary)
    
    Returns:
        API å“åº”å­—å…¸ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
    """
    # é€‰æ‹© Prompt æ¨¡æ¿
    prompt = PROMPT_TEMPLATES.get(style, PROMPT_TEMPLATES['casual'])
    
    # æ„å»º API è¯·æ±‚
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "glm-4v-flash",
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": f"data:image/jpeg;base64,{frame_base64}"
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ],
        "stream": False,
        "temperature": 0.7
    }
    
    try:
        print(f"ğŸ“¡ Calling GLM-4V API with {style} style...")
        response = requests.post(API_URL, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        data = response.json()
        
        if 'choices' in data and len(data['choices']) > 0:
            content = data['choices'][0]['message']['content']
            
            # è§£æ JSON å†…å®¹
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            
            if json_match:
                try:
                    result = json.loads(json_match.group())
                    print(f"âœ… API response received for {style} style")
                    return result
                except json.JSONDecodeError as e:
                    print(f"âŒ Failed to parse API response: {e}")
                    return None
        
        print(f"âŒ API response format unexpected")
        return None
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ API call failed: {e}")
        return None
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return None

# ============== è¯­è¨€å­¦å¤„ç† ==============
def process_linguistic_analysis(sentence: str) -> Dict:
    """è¯­è¨€å­¦åå¤„ç†ï¼ˆåˆ†è¯ã€éš¾åº¦åˆ†çº§ã€æ ¸å¿ƒè¯é€‰æ‹©ï¼‰
    
    Args:
        sentence: è¾“å…¥å¥å­
    
    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    import spacy
    from collections import Counter
    
    # åŠ è½½è‹±æ–‡è¯­è¨€æ¨¡å‹
    nlp = spacy.load('en_core_web_sm')
    
    # åˆ†è¯
    doc = nlp(sentence)
    tokens = [token for token in doc if not token.is_stop and not token.is_punct]
    
    # è¯æ€§æ ‡æ³¨
    pos_tags = [token.pos_ for token in tokens]
    
    # ç»Ÿè®¡è¯é¢‘
    word_freq = Counter(tokens)
    
    # è®¡ç®—æ¯ä¸ªè¯çš„ CEFR ç­‰çº§ï¼ˆä½¿ç”¨ wordfreqï¼‰
    advanced_vocabulary = []
    
    for token in set(tokens):
        word = token.text.lower()
        
        try:
            import wordfreq as wf
            zipf = wf.zipf_frequency(word)
            
            # CEFR åˆ†çº§
            if zipf >= 7.0:
                level = 'C1/C2'
            elif zipf >= 5.0:
                level = 'B2'
            elif zipf >= 3.0:
                level = 'B1/B2'
            else:
                level = 'A1/A2'
            
            # åªä¿ç•™é«˜çº§è¯æ±‡ï¼ˆB1 ä»¥ä¸Šï¼‰
            if level != 'A1/A2':
                pos = token.pos_
                
                advanced_vocabulary.append({
                    'word': word,
                    'lemma': token.lemma_ if hasattr(token, 'lemma_') else word,
                    'level': level,
                    'frequency': f"Zipf: {zipf:.2f}",
                    'pos': pos
                })
                
        except Exception as e:
            print(f"Warning: Could not determine level for {word}: {e}")
            continue
    
    # é€‰æ‹©æ ¸å¿ƒè¯ï¼ˆæœ€é«˜çº§è¯æ±‡ï¼‰
    if advanced_vocabulary:
        # æŒ‰ç­‰çº§æ’åºï¼ˆC1/C2 > B2 > B1/B2 > A1/A2ï¼‰
        level_order = {'C1/C2': 3, 'B2': 2, 'B1/B2': 1, 'A1/A2': 0}
        
        advanced_vocabulary.sort(
            key=lambda x: level_order.get(x['level'], 0),
            reverse=True
        )
        
        core_word = advanced_vocabulary[0]['word'] if advanced_vocabulary else ''
    else:
        core_word = ''
    
    return {
        'advanced_vocabulary': advanced_vocabulary,
        'vocabulary_count': len(advanced_vocabulary),
        'core_word': core_word
    }

# ============== ä¸»æµç¨‹ ==============
def main():
    print("="*50)
    print("ğŸ¬ VibeEnglish Video Analysis Script")
    print("="*50)
    print(f"ğŸ“ Frame Directory: {FRAME_DIR}")
    print(f"ğŸ“„ Output File: {OUTPUT_FILE}")
    print("="*50)
    
    # æ­¥éª¤ 1: è·å–è§†é¢‘å¸§
    print("\n" + "="*50)
    print("ğŸ“¸ Step 1: Getting video frames...")
    print("="*50)
    
    frames = get_video_frames(FRAME_DIR, max_frames=5)
    
    if not frames:
        print("âŒ No frames found. Please run frame extraction first.")
        return
    
    # æ­¥éª¤ 2: åˆ†ææ¯ä¸€å¸§
    print("\n" + "="*50)
    print("ğŸ¤– Step 2: Analyzing frames with GLM-4V...")
    print("="*50)
    
    all_narratives = []
    use_sliding_window = True
    style = 'casual'  # å¯é€‰: 'beginner', 'literary'
    
    for i, frame_base64 in enumerate(frames):
        print(f"\nğŸ“¸ Processing frame {i+1}/{len(frames)}...")
        
        # æ„å»º Promptï¼ˆå¦‚æœä½¿ç”¨æ»‘åŠ¨çª—å£ï¼‰
        if use_sliding_window and i > 0:
            previous_sentence = all_narratives[-1]['sentence']
            prompt = f"""### Context Continuity
The previous frame was described as: "{previous_sentence}"

### Instruction
Your description should:
1. Continue naturally from previous description
2. Maintain narrative coherence and flow
3. Describe what changed or what's new in this scene
4. Use consistent terminology (e.g., don't switch between "rabbit" and "bunny")

### Guidelines
- Use descriptive English (15-25 words)
- Focus on communication and meaning
- Include common contractions
- Be accurate with object detection
- Output ONLY valid JSON

### Output Format (Strict JSON ONLY)
{{
  "video_narrative": [
    {{
      "frame_index": {i},
      "timestamp": "{(i * 2).toString().padStart(2, '0')}:{(i * 2 % 60).toString().padStart(2, '0')}",
      "sentence": "Your descriptive sentence here."
    }}
  ],
  "detected_objects": [
    {{
      "label": "noun from your sentence",
      "boxes": [[ymin, xmin, ymax, xmax]]
    }}
  ]
}}"""
        else:
            prompt = PROMPT_TEMPLATES[style]
        
        # è°ƒç”¨ API
        api_result = call_glm_api(frame_base64, style)
        
        if api_result and 'video_narrative' in api_result:
            narrative = api_result['video_narrative'][0]
            
            # è¯­è¨€å­¦åå¤„ç†
            linguistic_result = process_linguistic_analysis(narrative['sentence'])
            
            all_narratives.append({
                'frame_index': i,
                'timestamp': f"{(i * 2).toString().padStart(2, '0')}:{(i * 2 % 60).toString().padStart(2, '0')}",
                'sentence': narrative['sentence'],
                'advanced_vocabulary': linguistic_result['advanced_vocabulary'],
                'core_word': linguistic_result['core_word'],
                'vocabulary_count': linguistic_result['vocabulary_count'],
                'context_continuity': {
                    'previous_sentence': all_narratives[i-1]['sentence'] if i > 0 else ''
                }
            })
            
            print(f"âœ… Frame {i+1} analyzed: {narrative['sentence'][:50]}...")
            print(f"   - Advanced vocab: {linguistic_result['vocabulary_count']} words")
            print(f"   - Core word: {linguistic_result['core_word']}")
        else:
            print(f"âŒ Failed to analyze frame {i+1}")
            continue
    
    # æ­¥éª¤ 3: ä¿å­˜ç»“æœ
    print("\n" + "="*50)
    print("ğŸ’¾ Step 3: Saving results...")
    print("="*50)
    
    final_result = {
        'video_narrative': all_narratives,
        'mode': 'sliding_window' if use_sliding_window else 'normal',
        'total_frames': len(frames),
        'style': style,
        'context_type': 'narrative_continuity' if use_sliding_window else 'none'
    }
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_result, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Results saved to {OUTPUT_FILE}")
    print(f"ğŸ“Š Total frames: {len(frames)}")
    print(f"ğŸ“Š Total advanced vocabulary: {sum(n['vocabulary_count'] for n in all_narratives)}")
    print(f"ğŸ“Š Average vocab per frame: {sum(n['vocabulary_count'] for n in all_narratives) / len(all_narratives):.1f}")
    
    print("\n" + "="*50)
    print("ğŸ‰ Analysis complete!")
    print("="*50)

if __name__ == "__main__":
    main()
