/**
 * å¹¶å‘å¤„ç†ä¼˜åŒ–æ¨¡å—
 * è‡ªé€‚åº”æ‰¹å¤§å°ã€æ™ºèƒ½é‡è¯•ã€è¿›åº¦æŒä¹…åŒ–
 */

import { CacheEntry } from './cache';

/**
 * ç½‘ç»œæ¡ä»¶è¯„ä¼°
 */
interface NetworkCondition {
  latency: 'low' | 'medium' | 'high';
  bandwidth: 'slow' | 'medium' | 'fast';
  reliability: number; // 0-1
}

/**
 * å¹¶å‘é…ç½®
 */
const CONCURRENCY_CONFIG = {
  // æ‰¹å¤§å°é…ç½®
  MIN_BATCH_SIZE: 3,               // æœ€å°æ‰¹æ¬¡å¤§å°
  MAX_BATCH_SIZE: 10,              // æœ€å¤§æ‰¹æ¬¡å¤§å°
  ADAPTIVE_STEP: 1,               // æ¯æ¬¡è°ƒæ•´æ­¥é•¿

  // é‡è¯•ç­–ç•¥
  MAX_RETRY_ATTEMPTS: 5,         // æœ€å¤§é‡è¯•æ¬¡æ•°
  BASE_RETRY_DELAY: 1000,          // åŸºç¡€é‡è¯•å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
  MAX_RETRY_DELAY: 10000,          // æœ€å¤§é‡è¯•å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
  RETRY_BACKOFF: 2.0,             // é€€é¿å› å­

  // å¹¶å‘æ§åˆ¶
  MAX_CONCURRENT_REQUESTS: 10,     // æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
  MAX_QUEUE_SIZE: 50,               // æœ€å¤§é˜Ÿåˆ—å¤§å°

  // è¶…æ—¶æ§åˆ¶
  REQUEST_TIMEOUT: 30000,           // å•ä¸ªè¯·æ±‚è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
  TOTAL_TIMEOUT: 300000,           // æ€»å¤„ç†è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰

  // èµ„æºé™åˆ¶
  MAX_MEMORY_MB: 512,             // æœ€å¤§å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰
  CLEANUP_THRESHOLD: 0.8           // æ¸…ç†é˜ˆå€¼ï¼ˆ80%ï¼‰
};

/**
 * è¿›åº¦ä¿¡æ¯æ¥å£
 */
interface ProgressEntry {
  taskId: string;
  current: number;
  total: number;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  startTime: number;
  endTime?: number;
  errors: string[];
}

/**
 * ä¼˜åŒ–å¤„ç†ç®¡ç†å™¨
 */
export class OptimizedProcessor {
  private activeRequests: Map<string, Promise<any>> = new Map();
  private requestQueue: Array<{ taskId: string; promise: Promise<any> }> = [];
  private networkCondition: NetworkCondition = {
    latency: 'medium',
    bandwidth: 'medium',
    reliability: 1.0
  };

  /**
   * è¯„ä¼°ç½‘ç»œæ¡ä»¶
   */
  async assessNetworkCondition(): Promise<void> {
    console.log('ğŸ“¡ Assessing network conditions...');

    const startTime = Date.now();
    const testUrl = 'https://httpbin.org/post';

    try {
      const response = await fetch(testUrl, {
        method: 'POST',
        body: JSON.stringify({ test: 'ping' }),
        signal: AbortSignal.timeout(5000)
      });

      const endTime = Date.now();
      const latency = endTime - startTime;

      // è¯„ä¼°å»¶è¿Ÿ
      if (latency < 500) {
        this.networkCondition.latency = 'low';
        this.networkCondition.bandwidth = 'fast';
      } else if (latency < 1500) {
        this.networkCondition.latency = 'medium';
        this.networkCondition.bandwidth = 'medium';
      } else {
        this.networkCondition.latency = 'high';
        this.networkCondition.bandwidth = 'slow';
      }

      this.networkCondition.reliability = response.ok ? 1.0 : 0.5;

      console.log(`âœ… Network assessed: latency=${latency}ms (${this.networkCondition.latency})`);

    } catch (error) {
      console.error('âŒ Network assessment failed:', error);
      this.networkCondition.latency = 'high';
      this.networkCondition.bandwidth = 'slow';
      this.networkCondition.reliability = 0.3;
    }
  }

  /**
   * è®¡ç®—è‡ªé€‚åº”æ‰¹å¤§å°
   */
  calculateAdaptiveBatchSize(): number {
    const { latency, bandwidth, reliability } = this.networkCondition;

    let batchSize = CONCURRENCY_CONFIG.MIN_BATCH_SIZE;

    // æ ¹æ®å»¶è¿Ÿè°ƒæ•´
    if (latency === 'low') {
      batchSize += 4; // ä½å»¶è¿Ÿå¯ä»¥å¤„ç†æ›´å¤§çš„æ‰¹æ¬¡
    } else if (latency === 'medium') {
      batchSize += 2;
    } else if (latency === 'high') {
      batchSize += 0; // é«˜å»¶è¿Ÿä¿æŒå°æ‰¹æ¬¡
    }

    // æ ¹æ®å¸¦å®½è°ƒæ•´
    if (bandwidth === 'fast') {
      batchSize += 2;
    } else if (bandwidth === 'slow') {
      batchSize -= 1;
    }

    // æ ¹æ®å¯é æ€§è°ƒæ•´
    batchSize = Math.floor(batchSize * reliability);

    // é™åˆ¶åœ¨èŒƒå›´å†…
    return Math.max(
      CONCURRENCY_CONFIG.MIN_BATCH_SIZE,
      Math.min(batchSize, CONCURRENCY_CONFIG.MAX_BATCH_SIZE)
    );
  }

  /**
   * è®¡ç®—æ™ºèƒ½é‡è¯•å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ + æŠ–åŠ¨ï¼‰
   */
  calculateRetryDelay(attempt: number): number {
    // æŒ‡æ•°é€€é¿
    const backoffDelay = Math.min(
      CONCURRENCY_CONFIG.MAX_RETRY_DELAY,
      CONCURRENCY_CONFIG.BASE_RETRY_DELAY * Math.pow(CONCURRENCY_CONFIG.RETRY_BACKOFF, attempt - 1)
    );

    // æ·»åŠ éšæœºæŠ–åŠ¨ï¼ˆé¿å…é›·ç¾¤æ•ˆåº”ï¼‰
    const jitter = Math.random() * 1000; // 0-1 ç§’æŠ–åŠ¨

    return Math.floor(backoffDelay + jitter);
  }

  /**
   * å¹¶å‘å¤„ç†å¸§ï¼ˆå¸¦ä¼˜åŒ–ï¼‰
   */
  async processFramesOptimized(
    frames: string[],
    style: string,
    useSlidingWindow: boolean,
    onProgress?: (current: number, total: number, batch: number) => void
  ): Promise<{
    results: any[];
    failedFrames: number[];
    networkCondition: NetworkCondition;
    totalProcessingTime: number;
  }> {
    const startTime = Date.now();

    // è¯„ä¼°ç½‘ç»œæ¡ä»¶
    await this.assessNetworkCondition();
    const batchSize = this.calculateAdaptiveBatchSize();

    console.log(`ğŸ“Š Network condition: ${JSON.stringify(this.networkCondition)}`);
    console.log(`ğŸ“Š Adaptive batch size: ${batchSize}`);

    // æ£€æŸ¥å¹¶å‘é™åˆ¶
    const activeCount = this.activeRequests.size;
    if (activeCount >= CONCURRENCY_CONFIG.MAX_CONCURRENT_REQUESTS) {
      console.warn(`âš ï¸  Concurrent limit reached (${activeCount}), queueing requests`);
    }

    const allResults: any[] = [];
    const allFailedFrames: number[] = [];
    let processedCount = 0;
    const totalFrames = frames.length;
    const batchCount = Math.ceil(totalFrames / batchSize);

    // åˆ†æ‰¹å¤„ç†
    for (let batchIndex = 0; batchIndex < batchCount; batchIndex++) {
      const batchStart = batchIndex * batchSize;
      const batchEnd = Math.min((batchIndex + 1) * batchSize, totalFrames);
      const batchFrames = frames.slice(batchStart, batchEnd);

      console.log(`ğŸ”„ Processing batch ${batchIndex + 1}/${batchCount}: frames ${batchStart}-${batchEnd}`);

      try {
        // ç­‰å¾…å¯ç”¨å¹¶å‘æ§½
        while (this.activeRequests.size >= CONCURRENCY_CONFIG.MAX_CONCURRENT_REQUESTS) {
          console.log(`â³ Waiting for available slots... (${this.activeRequests.size}/${CONCURRENCY_CONFIG.MAX_CONCURRENT_REQUESTS})`);
          await new Promise(resolve => setTimeout(resolve, 100));
        }

        // åˆ›å»ºæ‰¹å¤„ç† Promise
        const batchPromises = batchFrames.map((frame, frameIndex) => {
          const taskId = `frame_${batchStart + frameIndex}_${Date.now()}`;
          
          const promise = this.processFrameWithRetry(
            frame,
            batchStart + frameIndex,
            style,
            useSlidingWindow,
            taskId
          ).then(result => {
            this.activeRequests.delete(taskId);
            return result;
          }).catch(error => {
            this.activeRequests.delete(taskId);
            throw error;
          });

          this.activeRequests.set(taskId, promise);
          return promise;
        });

        // ç­‰å¾…æ‰¹å®Œæˆ
        const batchResults = await Promise.all(batchPromises);

        // å¤„ç†ç»“æœ
        const batchSuccessful = batchResults.filter(r => !r.error);
        const batchFailed = batchResults.filter(r => r.error);

        allResults.push(...batchSuccessful);
        allFailedFrames.push(...batchFailed.map((r, idx) => batchStart + idx));

        processedCount = batchEnd;

        // æŠ¥å‘Šè¿›åº¦
        if (onProgress) {
          onProgress(processedCount, totalFrames, batchIndex + 1);
        }

        // æ‰¹æ¬¡é—´å»¶è¿Ÿï¼ˆé¿å…è¿‡è½½ï¼‰
        if (batchIndex < batchCount - 1) {
          const delay = this.networkCondition.latency === 'low' ? 500 : 1000;
          await new Promise(resolve => setTimeout(resolve, delay));
        }

      } catch (error) {
        console.error(`âŒ Batch ${batchIndex + 1} failed:`, error);
        // æ•´æ‰¹å¤±è´¥
        batchFrames.forEach((_, frameIndex) => {
          allFailedFrames.push(batchStart + frameIndex);
        });
      }
    }

    const totalProcessingTime = Date.now() - startTime;

    console.log(`âœ… Optimized processing complete`);
    console.log(`ğŸ“Š Total time: ${totalProcessingTime}ms`);
    console.log(`ğŸ“Š Success: ${allResults.length}/${totalFrames}`);
    console.log(`ğŸ“Š Failed: ${allFailedFrames.length}/${totalFrames}`);

    return {
      results: allResults,
      failedFrames: allFailedFrames,
      networkCondition: this.networkCondition,
      totalProcessingTime
    };
  }

  /**
   * å¤„ç†å•ä¸ªå¸§ï¼ˆå¸¦æ™ºèƒ½é‡è¯•ï¼‰
   */
  private async processFrameWithRetry(
    frame: string,
    frameIndex: number,
    style: string,
    useSlidingWindow: boolean,
    taskId: string
  ): Promise<any> {
    let lastError: Error | null = null;

    for (let attempt = 0; attempt < CONCURRENCY_CONFIG.MAX_RETRY_ATTEMPTS; attempt++) {
      try {
        const startTime = Date.now();

        // è°ƒç”¨åˆ†æ API
        const response = await fetch('/api/analyze-frame', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          'X-Request-ID': taskId,
            'X-Attempt-Number': String(attempt + 1)
          },
          body: JSON.stringify({
            frame,
            index: frameIndex,
            style,
            useSlidingWindow
          }),
          signal: AbortSignal.timeout(CONCURRENCY_CONFIG.REQUEST_TIMEOUT)
        });

        const endTime = Date.now();
        const processingTime = endTime - startTime;

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }

        const data = await response.json();

        if (!data.success) {
          throw new Error(data.error || 'Analysis failed');
        }

        // æˆåŠŸè¿”å›ç»“æœ
        console.log(`âœ“ Frame ${frameIndex} (attempt ${attempt + 1}): ${processingTime}ms`);
        
        return {
          ...data.data,
          processingTime,
          attempt: attempt + 1,
          taskId
        };

      } catch (error) {
        lastError = error as Error;
        console.warn(`âš ï¸  Frame ${frameIndex} attempt ${attempt + 1} failed:`, error.message);

        // æœ€åä¸€æ¬¡å°è¯•å¤±è´¥åè¿”å›é”™è¯¯
        if (attempt < CONCURRENCY_CONFIG.MAX_RETRY_ATTEMPTS - 1) {
          const delay = this.calculateRetryDelay(attempt);
          console.log(`â³ Retrying in ${delay}ms...`);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }

    // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ç»“æœ
    console.error(`âŒ Frame ${frameIndex} failed after ${CONCURRENCY_CONFIG.MAX_RETRY_ATTEMPTS} attempts`);

    return {
      error: true,
      message: lastError?.message || 'Max retries exceeded',
      attempts: CONCURRENCY_CONFIG.MAX_RETRY_ATTEMPTS,
      taskId
    };
  }

  /**
   * ä¿å­˜è¿›åº¦åˆ° IndexedDB
   */
  async saveProgress(progress: ProgressEntry): Promise<void> {
    // è¿™é‡Œåº”è¯¥ä¿å­˜åˆ° IndexedDB
    // æš‚æ—¶åªè®°å½•åˆ° console
    console.log(`ğŸ’¾ Saving progress: ${progress.taskId} (${progress.current}/${progress.total}) - ${progress.status}`);
  }

  /**
   * ä» IndexedDB åŠ è½½è¿›åº¦
   */
  async loadProgress(taskId: string): Promise<ProgressEntry | null> {
    // è¿™é‡Œåº”è¯¥ä» IndexedDB åŠ è½½
    console.log(`ğŸ“‚ Loading progress for: ${taskId}`);
    return null;
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup(): void {
    console.log('ğŸ§¹ Cleaning up optimized processor...');

    // å–æ¶ˆæ‰€æœ‰æ´»è·ƒè¯·æ±‚
    this.activeRequests.forEach((promise, taskId) => {
      console.log(`ğŸš« Cancelling request: ${taskId}`);
      // æ³¨æ„ï¼šAbortController åœ¨å®é™…å®ç°ä¸­éœ€è¦
    });

    this.activeRequests.clear();
    this.requestQueue = [];
  }

  /**
   * è·å–æ€§èƒ½ç»Ÿè®¡
   */
  getPerformanceStats(): {
    activeRequests: number;
    queuedRequests: number;
    networkCondition: NetworkCondition;
    adaptiveBatchSize: number;
  } {
    return {
      activeRequests: this.activeRequests.size,
      queuedRequests: this.requestQueue.length,
      networkCondition: this.networkCondition,
      adaptiveBatchSize: this.calculateAdaptiveBatchSize()
    };
  }
}
